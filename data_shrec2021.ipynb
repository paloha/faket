{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37efdc36-efcc-479a-9a62-a7eaf087fc15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Naming convention and contents of the created files\n",
    "\n",
    "1. `faket/class_mask.mrc` = `class_mask.mrc` sliced to valid region.\n",
    "1. `faket/occupancy_mask.mrc` = `occupancy_mask.mrc` slice to valid region.\n",
    "1. `reconstruction.mrc` = `faket/reconstruction_shrec.mrc` slice to valid region for tomogram 9.\n",
    "1. `faket/projections_noiseless.mrc` = `grandmodel_unbinned.mrc` measured with Radon transform.\n",
    "1. `faket/projections_content.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.1) shifted & scaled according its style*.\n",
    "1. `faket/projections_noisy.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.4) shifted & scaled according its style*.\n",
    "1. `faket/projections_styled.mrc` = result of NST initialized with `faket/projections_noisy.mrc`, content `faket/projections_content.mrc`, and using its style*.\n",
    "1. `faket/reconstruction_content.mrc` = reconstruction of `faket/projections_content.mrc`.\n",
    "1. `faket/reconstruction_noisy.mrc` = reconstruction of `faket/projections_noisy.mrc`.\n",
    "1. `faket/reconstruction_styled.mrc` = reconstruction of `faket/projections_styled.mrc`.\n",
    "1. `faket/reconstruction_baseline.mrc` = reconstruction of `projections.mrc`.\n",
    "\n",
    "\\* Each time we mention style in the text above, it refers to a `projections.mrc` file from a model_N+1. In case N=8, the style is taken from N=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f9ad8-f0b4-48cb-a439-c3f3d2ba6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "import gpuMultiprocessing\n",
    "from src.data import load_mrc, save_mrc\n",
    "from src.data import slice_to_valid, vol_to_valid\n",
    "from src.data import downsample_sinogram_space\n",
    "from src.data import get_clim, get_theta\n",
    "from src.data import match_mean_std, normalize\n",
    "from src.transform import radon_3d, reconstruct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba7269-c7a8-4ada-8cde-2a4893c101a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/shrec2021_extended_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63139552-e378-494b-ad7a-aff7fd6f72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHREC21 provides the data in square shape even\n",
    "# thought the data is stored only in the center\n",
    "# The following values specify where to slice\n",
    "z_valid = (0.32226, 0.67382)  # Valid range normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b557c4-bd47-44d5-80b0-f1e5151c32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice class_mask.mrc to faket/class_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, N, 'class_mask', z_valid, \n",
    "                 out_fname='faket/class_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66b8d9-1636-4ddd-853f-f34ff7012ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice occupancy_mask.mrc to faket/occupancy_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, N, 'occupancy_mask', z_valid, \n",
    "                 out_fname='faket/occupancy_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce1262-c1e2-4cea-b7d2-90d178bb362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice reconstruction.mrc to faket/reconstruction_shrec.mrc\n",
    "vol_to_valid(data_folder, 9, 'reconstruction', z_valid, \n",
    "                 out_fname='faket/reconstruction_shrec.mrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087354b7-0d6d-4a99-8170-3ddb28916046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdde34-b4f6-4c99-a6b6-53d9b6931c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_noiseless.mrc by measuring the grandmodel_unbinned.mrc with Radon transform\n",
    "dose = 0\n",
    "for N in range(0, 9): # We do not need this modality for the test model_9\n",
    "    print(f'Processing N: {N}')\n",
    "    volume = load_mrc(data_folder, N, 'grandmodel_unbinned.mrc')\n",
    "    theta = get_theta(data_folder, N)\n",
    "    # Circle = False because we measure with the data outside the circle \n",
    "    # but later we cut the measurements to desired shape (SHREC did it this way - confirmed from a call)\n",
    "    sinogram = radon_3d(volume, theta, dose=dose, out_shape=1024, slice_axis=1, circle=False)\n",
    "    save_mrc(sinogram.astype(np.float32), data_folder, N, \n",
    "             'faket/projections_noiseless.mrc', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b494162-57ba-4e57-b1fe-b292f7f6d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_content.mrc and faket/projections_noisy.mrc\n",
    "for N in range(0, 9): # We do not need this modality for the test model_9\n",
    "    print(f'Processing N: {N}')\n",
    "    volume = load_mrc(data_folder, N, 'faket/projections_noiseless.mrc')\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    style = load_mrc(data_folder, style_N, 'projections.mrc')\n",
    "    \n",
    "    rng = np.random.default_rng(seed=N)\n",
    "    noise = rng.normal(loc=0.0, scale=0.4, size=volume.size).reshape(volume.shape)\n",
    "    \n",
    "    volume  = match_mean_std(volume, style)  # Scaling per tilt (bigger the abs(angle), longer the trajectory)\n",
    "    volume = normalize(volume)  # Scale between [0, 1]\n",
    "    \n",
    "    volume_noisy = volume + noise\n",
    "    volume_noisy = np.clip(volume_noisy, *get_clim(volume_noisy, 0.0001, 0.9999))  # Remove outliers\n",
    "    volume_noisy = match_mean_std(volume_noisy, style)  # Scale back to match style\n",
    "    \n",
    "    save_mrc(volume_noisy.astype(np.float32), data_folder, N, \n",
    "             'faket/projections_noisy.mrc', overwrite=True)\n",
    "    \n",
    "    volume_content = volume + noise / 4  # Same noise just 1/4 of the std\n",
    "    volume_content = np.clip(volume_content, *get_clim(volume_content, 0.0001, 0.9999))  # Remove outliers\n",
    "    volume_content = match_mean_std(volume_content, style)  # Scale back to match style\n",
    "    \n",
    "    save_mrc(volume_content.astype(np.float32), data_folder, N, \n",
    "             'faket/projections_content.mrc', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248df2ef-3676-4052-86a6-0947bf7b0ca5",
   "metadata": {},
   "source": [
    "### Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927792d-dd97-409b-a1c6-67e7952f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstc = {  # NEURAL STYLE TRANSFER BASE CONFIG\n",
    "    # 'content': 'example.mrc',\n",
    "    # 'style': 'example.mrc',\n",
    "    # '--init': 'example.mrc',\n",
    "    # '--output': 'example.mrc', \n",
    "    # '--random-seed': None,\n",
    "    '--style-weights': 1.0,\n",
    "    '--content-weight': 1.0, \n",
    "    '--tv-weight': 0,\n",
    "    '--min-scale': 1024,\n",
    "    '--end-scale': 1024,\n",
    "    '--iterations': 1,\n",
    "    '--initial-iterations': 1,\n",
    "    '--save-every': 2,\n",
    "    '--step-size': 0.15,\n",
    "    '--avg-decay': 0.99,\n",
    "    '--style-scale-fac': 1.0,\n",
    "    '--pooling': 'max',\n",
    "    '--devices': 'cuda:0',\n",
    "    '--seq_start' : 0,\n",
    "    '--seq_end' : 61,\n",
    "}\n",
    "\n",
    "def get_command(expname, nst_command, config):\n",
    "    command = (\n",
    "    f\"EXPNAME={expname} {nst_command} \"\n",
    "    f\"{config['content']} {config['style']} \"\n",
    "    f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])}\")\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94bfe9-cecf-4260-b185-843fa356d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_styled.mrc\n",
    "gpu_id_list = [6]\n",
    "NST_command = 'python3 style_transfer/cli.py'\n",
    "\n",
    "command_queue = []\n",
    "for N in range(0, 9): # We do not need this modality for the test model_9\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    \n",
    "    EXPNAME = f'TOMOGRAM_{N}'  # Just for visualizing the progress\n",
    "    tomo_folder = os.path.join(data_folder, f'model_{N}', 'faket')\n",
    "\n",
    "    conf = nstc.copy()\n",
    "    conf.update({\n",
    "        'content': os.path.join(tomo_folder, 'projections_content.mrc'),\n",
    "        'style': os.path.join(data_folder, f'model_{style_N}', 'projections.mrc'), \n",
    "        '--init': os.path.join(tomo_folder, 'projections_noisy.mrc'),\n",
    "        '--output': os.path.join(tomo_folder, 'projections_styled.mrc'), \n",
    "        '--random-seed': N,\n",
    "    })\n",
    "    \n",
    "    command = get_command(EXPNAME, NST_command, conf)\n",
    "    command_queue.append(command)\n",
    "    \n",
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=6, allowed_restarts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808e94a-4e7b-439c-ad2b-c0fac8ed86be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computing reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63637366-ba08-408e-8dc2-473fd13a328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recc = {  # RECONSTRUCTION BASE CONFIG\n",
    "    'downsample_angle' : 1,  # Sinogram downsampling in theta dimension (1 = no downsampling)\n",
    "    'downsample_pre' : 2,  # Sinogram downsampling (1 = no downsampling)\n",
    "    'order' : 3,  # Downsampling in space with spline interpolation of order (0 - 5)\n",
    "    'filter' : 'ramp2d',  # Filter userd during reconstruction in FBP algorithm\n",
    "    'filterkwargs' : {'crowtherFreq': 25, 'radiusCutoff': 230, 'angularCutoff': (0, 83)},\n",
    "    'downsample_post' : 1,  # Reconstruction downsampling\n",
    "    'ncpus': 61, # multiprocessing.cpu_count(),  # Number of CPUs to use while reconstructing\n",
    "    'z_valid': z_valid # 2-tuple range of valid pixels in Z dimension normalized from 0 to 1. (0., 1.) or None for all.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cc94e-b2ab-44b7-982d-bbfc0a90a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_content.mrc to produce faket/reconstruction_content.mrc\n",
    "for N in range(0, 9):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : 'faket/projections_content.mrc', \n",
    "        'output_mrc' : 'faket/reconstruction_content.mrc'\n",
    "    })\n",
    "    reconstruct(data_folder, N, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b252a9-1d7f-4357-9e70-2f068a815f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_noisy.mrc to produce faket/reconstruction_noisy.mrc\n",
    "for N in range(0, 9):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : 'faket/projections_noisy.mrc', \n",
    "        'output_mrc' : 'faket/reconstruction_noisy.mrc'\n",
    "    })\n",
    "    reconstruct(data_folder, N, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c2fbf-abf6-4316-a492-b92601a7c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_styled.mrc to produce faket/reconstruction_styled.mrc\n",
    "for N in range(0, 9):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : 'faket/projections_styled.mrc', \n",
    "        'output_mrc' : 'faket/reconstruction_styled.mrc'\n",
    "    })\n",
    "    reconstruct(data_folder, N, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68c034-b3e5-4f7b-9c3e-567b57e3b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct projections.mrc to produce faket/reconstruction_baseline.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : 'projections.mrc', \n",
    "        'output_mrc' : 'faket/reconstruction_baseline.mrc'\n",
    "    })\n",
    "    reconstruct(data_folder, N, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6dd1b-e678-4874-99ce-d3ed44155600",
   "metadata": {},
   "source": [
    "# Deep Finder experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc0979-d85b-4ecf-aa53-826ef61833b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEPARATE (for sure save the model after 15 and 30 epochs)\n",
    "# 1. DF('faket/reconstruction_baseline.mrc')  30 epochs on 9 tomograms\n",
    "# 2. DF('faket/reconstruction_content.mrc')   30 epochs on 9 tomograms\n",
    "# 3. DF('faket/reconstruction_noisy.mrc')     30 epochs on 9 tomograms\n",
    "# 4. DF('faket/reconstruction_styled.mrc')    30 epochs on 9 tomograms\n",
    "\n",
    "## FINETUNING (pre-train on synthetic & finetune on \"real\")\n",
    "# 5. take model from step 2. saved at 15 epochs and finetune on 'faket/reconstruction_baseline.mrc' for 15 epochs\n",
    "# 6. take model from step 3. saved at 15 epochs and finetune on 'faket/reconstruction_baseline.mrc' for 15 epochs\n",
    "# 7. take model from step 4. saved at 15 epochs and finetune on 'faket/reconstruction_baseline.mrc' for 15 epochs\n",
    "\n",
    "## AUGMENTATION\n",
    "# 8. DF('faket/reconstruction_content.mrc'[0, 1, 2, 3, 4] & 'faket/reconstruction_baseline.mrc'[5, 6, 7, 8]) for 30 ep.\n",
    "# 9. DF('faket/reconstruction_noisy.mrc'[0, 1, 2, 3, 4] & 'faket/reconstruction_baseline.mrc'[5, 6, 7, 8]) for 30 ep.\n",
    "# 10. DF('faket/reconstruction_styled.mrc'[0, 1, 2, 3, 4] & 'faket/reconstruction_baseline.mrc'[5, 6, 7, 8]) for 30 ep.\n",
    "\n",
    "# TEST on 'faket/reconstruction_baseline.mrc'\n",
    "# TEST on 'faket/reconstruction_shrec.mrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e91d7-4f51-4d44-87a4-2589d479b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script=\"\"\"\n",
    "for idx in 1 2 3 4 5 6 7; \n",
    "do \n",
    "    PYTHONHASHSEED=0 python deepfinder/launch_training.py --path_config results/experiment_${idx}a/\n",
    "done\n",
    "\n",
    "for idx in 1 5 6 7; \n",
    "do \n",
    "    PYTHONHASHSEED=0 python deepfinder/launch_training.py --path_config results/experiment_${idx}b/\n",
    "done\n",
    "\"\"\"\n",
    "with open('train_script.sh', 'w') as file:\n",
    "  file.write(train_script)\n",
    "\n",
    "!bash train_script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13eceae-423d-475f-9e5b-0fddc2dcb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation step on GPU with ID GPU_no\n",
    "!python deepfinder/step1_launch_segment_loop.py --path_config results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2fb57-e956-404b-8471-1f456077f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run clustering \n",
    "!python deepfinder/step2_clustering_loop.py --path_config results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df298953-94b2-4b1d-a758-36c0b90b5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deepfinder/step3_launch_evaluation.py --path_config results/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
