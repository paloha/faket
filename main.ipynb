{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37efdc36-efcc-479a-9a62-a7eaf087fc15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Naming convention and contents of the created files\n",
    "\n",
    "1. `faket/class_mask.mrc` = `class_mask.mrc` sliced to valid region.\n",
    "1. `faket/occupancy_mask.mrc` = `occupancy_mask.mrc` slice to valid region.\n",
    "1. `reconstruction.mrc` = `faket/reconstruction_shrec.mrc` slice to valid region for tomogram 9.\n",
    "1. `faket/projections_noiseless.mrc` = `grandmodel_unbinned.mrc` measured with Radon transform.\n",
    "1. `faket/projections_content.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.1) shifted & scaled according its style*.\n",
    "1. `faket/projections_noisy.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.4) shifted & scaled according its style*.\n",
    "1. `faket/projections_styled.mrc` = result of NST initialized with `faket/projections_noisy.mrc`, content `faket/projections_content.mrc`, and using its style*.\n",
    "1. `faket/reconstruction_content.mrc` = reconstruction of `faket/projections_content.mrc`.\n",
    "1. `faket/reconstruction_noisy.mrc` = reconstruction of `faket/projections_noisy.mrc`.\n",
    "1. `faket/reconstruction_styled.mrc` = reconstruction of `faket/projections_styled.mrc`.\n",
    "1. `faket/reconstruction_baseline.mrc` = reconstruction of `projections.mrc`.\n",
    "\n",
    "\\* Each time we mention style in the text above, it refers to a `projections.mrc` file from a model_N+1. In case N=8, the style is taken from N=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f9ad8-f0b4-48cb-a439-c3f3d2ba6dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os.path import join as pj\n",
    "import multiprocessing\n",
    "import gpuMultiprocessing\n",
    "from faket.data import load_mrc, save_mrc, save_conf\n",
    "from faket.data import slice_to_valid, vol_to_valid\n",
    "from faket.data import downsample_sinogram_space\n",
    "from faket.data import get_clim, get_theta\n",
    "from faket.data import match_mean_std, normalize\n",
    "from faket.transform import radon_3d, reconstruct_mrc\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba7269-c7a8-4ada-8cde-2a4893c101a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/shrec2021_extended_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63139552-e378-494b-ad7a-aff7fd6f72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHREC21 provides the data in square shape even\n",
    "# thought the data is stored only in the center\n",
    "# The following values specify where to slice\n",
    "z_valid = (0.32226, 0.67382)  # Valid range normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b557c4-bd47-44d5-80b0-f1e5151c32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice class_mask.mrc to faket/class_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, f'model_{N}', 'class_mask', z_valid, \n",
    "                 out_fname='faket/class_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66b8d9-1636-4ddd-853f-f34ff7012ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice occupancy_mask.mrc to faket/occupancy_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, f'model_{N}', 'occupancy_mask', z_valid, \n",
    "                 out_fname='faket/occupancy_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce1262-c1e2-4cea-b7d2-90d178bb362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice reconstruction.mrc to faket/reconstruction_shrec.mrc\n",
    "vol_to_valid(data_folder, f'model_9', 'reconstruction', z_valid, \n",
    "                 out_fname='faket/reconstruction_shrec.mrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087354b7-0d6d-4a99-8170-3ddb28916046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdde34-b4f6-4c99-a6b6-53d9b6931c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_noiseless.mrc by measuring the grandmodel_unbinned.mrc with Radon transform\n",
    "\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = {\n",
    "        'input_mrc': pj(data_folder, f'model_{N}', 'grandmodel_unbinned.mrc'),\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'),\n",
    "        'radon_kwargs': {\n",
    "            'theta': get_theta(data_folder, N),\n",
    "            'dose': 0,\n",
    "            'out_shape': 1024,\n",
    "            'slice_axis': 1,\n",
    "            # circle=False because we measure with the data outside the circle \n",
    "            # but later we cut the measurements to desired shape \n",
    "            # SHREC did it this way - confirmed from a personal communication\n",
    "            'circle': False\n",
    "        }\n",
    "    }\n",
    "    volume = load_mrc(conf['input_mrc'])\n",
    "    sinogram = radon_3d(volume, **conf['radon_kwargs'])\n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    save_mrc(sinogram.astype(np.float32), conf['output_mrc'], overwrite=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b494162-57ba-4e57-b1fe-b292f7f6d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_content.mrc and faket/projections_noisy.mrc\n",
    "for N in range(0, 1): # We do not need this modality for the test model_9\n",
    "    print(f'Processing N: {N}')\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    \n",
    "    conf = {  # For noisy\n",
    "        'input_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'),\n",
    "        'style_mrc': pj(data_folder, f'model_{style_N}', 'projections.mrc'),\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noisy.mrc'),\n",
    "        'mean': 0.0,\n",
    "        'std': 0.4,\n",
    "        'clip_outliers': (0.0001, 0.9999),\n",
    "        'seed': N,\n",
    "    }\n",
    "    \n",
    "    conf2 = {  # Changes for content\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_content.mrc'),\n",
    "        'std': 0.1,\n",
    "    }\n",
    "    \n",
    "    volume = load_mrc(conf['input_mrc'])\n",
    "    style = load_mrc(conf['style_mrc'])\n",
    "    \n",
    "    rng = np.random.default_rng(seed=conf['seed'])\n",
    "    noise = rng.normal(loc=conf['mean'], scale=conf['std'], \n",
    "                       size=volume.size).reshape(volume.shape)\n",
    "    \n",
    "    volume  = match_mean_std(volume, style)  # Scaling per tilt (bigger the abs(angle), longer the trajectory)\n",
    "    volume = normalize(volume)  # Scale between [0, 1]\n",
    "    \n",
    "    volume_noisy = volume + noise\n",
    "    volume_noisy = np.clip(volume_noisy, *get_clim(volume_noisy, *conf['clip_outliers']))  # Remove outliers\n",
    "    volume_noisy = match_mean_std(volume_noisy, style)  # Scale back to match style\n",
    "    \n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    save_mrc(volume_noisy.astype(np.float32), conf['output_mrc'], overwrite=True)\n",
    "    \n",
    "    ratio = conf['std'] / conf2['std']\n",
    "    conf.update(conf2)\n",
    "    volume_content = volume + noise / ratio  # Same noise just a fraction of the std\n",
    "    volume_content = np.clip(volume_content, *get_clim(volume_content, *conf['clip_outliers']))  # Remove outliers\n",
    "    volume_content = match_mean_std(volume_content, style)  # Scale back to match style\n",
    "    \n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    save_mrc(volume_content.astype(np.float32), conf['output_mrc'], overwrite=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248df2ef-3676-4052-86a6-0947bf7b0ca5",
   "metadata": {},
   "source": [
    "### Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927792d-dd97-409b-a1c6-67e7952f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstc = {  # NEURAL STYLE TRANSFER BASE CONFIG\n",
    "    # 'content': 'example.mrc',\n",
    "    # 'style': 'example.mrc',\n",
    "    # '--init': 'example.mrc',\n",
    "    # '--output': 'example.mrc', \n",
    "    # '--random-seed': None,\n",
    "    '--style-weights': 1.0,\n",
    "    '--content-weight': 1.0, \n",
    "    '--tv-weight': 0,\n",
    "    '--min-scale': 1024,\n",
    "    '--end-scale': 1024,\n",
    "    '--iterations': 1,\n",
    "    '--initial-iterations': 1,\n",
    "    '--save-every': 2,\n",
    "    '--step-size': 0.15,\n",
    "    '--avg-decay': 0.99,\n",
    "    '--style-scale-fac': 1.0,\n",
    "    '--pooling': 'max',\n",
    "    '--devices': 'cuda:0', #\n",
    "    '--seq_start' : 0,\n",
    "    '--seq_end' : 61,\n",
    "}\n",
    "\n",
    "def get_command(expname, nst_command, config):\n",
    "    command = (\n",
    "    f\"EXPNAME={expname} {nst_command} \"\n",
    "    f\"{config['content']} {config['style']} \"\n",
    "    f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])}\")\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94bfe9-cecf-4260-b185-843fa356d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_styled.mrc\n",
    "gpu_id_list = [0]\n",
    "NST_command = 'python3 -m faket.style_transfer.cli'\n",
    "\n",
    "command_queue = []\n",
    "for N in range(0, 10): # We do not need this modality for the test model_9\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    \n",
    "    EXPNAME = f'TOMOGRAM_{N}'  # Just for visualizing the progress\n",
    "    tomo_folder = pj(data_folder, f'model_{N}', 'faket')\n",
    "\n",
    "    conf = nstc.copy()\n",
    "    conf.update({\n",
    "        'content': pj(tomo_folder, 'projections_content.mrc'),\n",
    "        'style': pj(data_folder, f'model_{style_N}', 'projections.mrc'), \n",
    "        '--init': pj(tomo_folder, 'projections_noisy.mrc'),\n",
    "        '--output': pj(tomo_folder, 'projections_styled.mrc'), \n",
    "        '--random-seed': N,\n",
    "    })\n",
    "    \n",
    "    command = get_command(EXPNAME, NST_command, conf)\n",
    "    command_queue.append(command)\n",
    "    \n",
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=6, allowed_restarts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808e94a-4e7b-439c-ad2b-c0fac8ed86be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computing reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63637366-ba08-408e-8dc2-473fd13a328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recc = {  # RECONSTRUCTION BASE CONFIG\n",
    "    'downsample_angle' : 1,  # Sinogram downsampling in theta dimension (1 = no downsampling)\n",
    "    'downsample_pre' : 2,  # Sinogram downsampling (1 = no downsampling)\n",
    "    'order' : 3,  # Downsampling in space with spline interpolation of order (0 - 5)\n",
    "    'filtering' : 'ramp2d',  # Filter userd during reconstruction in FBP algorithm\n",
    "    'filterkwargs' : {'crowtherFreq': 25, 'radiusCutoff': 230, 'angularCutoff': (0, 83)},\n",
    "    'downsample_post' : 1,  # Reconstruction downsampling\n",
    "    'ncpus': 61, # multiprocessing.cpu_count(),  # Number of CPUs to use while reconstructing\n",
    "    'z_valid': z_valid # 2-tuple range of valid pixels in Z dimension normalized from 0 to 1. (0., 1.) or None for all.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cc94e-b2ab-44b7-982d-bbfc0a90a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_content.mrc to produce faket/reconstruction_content.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'faket/projections_content.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' :  pj(data_folder, f'model_{N}', 'faket/reconstruction_content.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b252a9-1d7f-4357-9e70-2f068a815f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_noisy.mrc to produce faket/reconstruction_noisy.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : pj(data_folder, f'model_{N}', 'faket/projections_noisy.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_noisy.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c2fbf-abf6-4316-a492-b92601a7c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_styled.mrc to produce faket/reconstruction_styled.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : pj(data_folder, f'model_{N}', 'faket/projections_styled.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_styled.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68c034-b3e5-4f7b-9c3e-567b57e3b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct projections.mrc to produce faket/reconstruction_baseline.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'projections.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_baseline.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037af53-80ca-4a9c-a2c2-8682d308454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_noiseless.mrc to produce faket/reconstruction_noiseless.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_noiseless.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6dd1b-e678-4874-99ce-d3ed44155600",
   "metadata": {},
   "source": [
    "# Deep Finder experiments\n",
    "\n",
    "1. `DF('faket/reconstruction_baseline.mrc')` - train for 30 epochs on 9 tomograms, eval on test tomogram every 5 epochs\n",
    "2. `DF('faket/reconstruction_content.mrc')` - train for 30 epochs on 9 tomograms, eval on test tomogram every 5 epochs\n",
    "3. `DF('faket/reconstruction_noisy.mrc')` - train for 30 epochs on 9 tomograms, eval on test tomogram every 5 epochs\n",
    "4. `DF('faket/reconstruction_styled.mrc')` - train for 30 epochs on 9 tomograms, eval on test tomogram every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd24e0-26a1-45f0-a14b-be83636f07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c78ccc-cd0b-462d-96fc-d4b517bdb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_DF_training_command(tomo_path, DF_training_command, config):\n",
    "    command = (\n",
    "        f\"{DF_training_command} \"\n",
    "        f\"--training_tomogram_ids {' '.join(list(zip(*config['training_tomograms']))[0])} \"\n",
    "        f\"--training_tomograms {' '.join(list(zip(*config['training_tomograms']))[1])} \"\n",
    "        f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])} \"       \n",
    "    )\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa266a-6e18-44ef-997b-4944b527e5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_id_list = [0]\n",
    "tomo_path = 'data/shrec2021_extended_dataset/'\n",
    "DF_training_command ='PYTHONHASHSEED=0 python faket/deepfinder/launch_training.py'\n",
    "\n",
    "# create config files from dict using json for different seeds\n",
    "experiment_name = \"exp1\"\n",
    "num_seeds = 1\n",
    "\n",
    "command_queue = []\n",
    "\n",
    "for N in range(1,num_seeds+1):\n",
    "    training_conf ={\n",
    "        \"--training_tomo_path\" : tomo_path,\n",
    "        \"training_tomograms\" : [[str(i),\"baseline\"] for i in range(0,9)],\n",
    "        \"--num_epochs\" : 2,\n",
    "        \"--out_path\" : \"results/\" + experiment_name + \"/seed\" + str(N) + \"/\",\n",
    "        \"--save_every\" : 1, \n",
    "        \"--seed1\" : \"1\" + str(N) + \"2\",\n",
    "        \"--seed2\" : \"1\" + str(N) + \"23\",\n",
    "    }\n",
    "    \n",
    "    command = get_full_DF_training_command(tomo_path, DF_training_command, training_conf)\n",
    "    command_queue.append(command)\n",
    "\n",
    "    \n",
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bf698-b2ae-44de-8574-265ec3913ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_DF_analysis_command(DF_analysis_command, config):\n",
    "    command=(\n",
    "        f\"{DF_analysis_command} \"\n",
    "        f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])} \"\n",
    "    )\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537ca48-9d2b-429f-a4c8-a6dd97b4be2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_id_list = [1]\n",
    "tomo_path = 'data/shrec2021_extended_dataset/'\n",
    "DF_segmentation_command ='python faket/deepfinder/launch_segmentation.py'\n",
    "\n",
    "experiment_name = \"exp1\"\n",
    "seed_ids = [1, 2]\n",
    "num_epochs = [1,2]\n",
    "test_tomograms = [\"baseline\"]\n",
    "test_tomograms_idx = 9\n",
    "\n",
    "command_queue = []\n",
    "\n",
    "for N, num_epoch, test_tomogram in product(seed_ids, num_epochs, test_tomograms):\n",
    "    analysis_conf ={\n",
    "        \"--test_tomo_path\" : tomo_path,\n",
    "        \"--test_tomo_idx\" : 9, \n",
    "        \"--test_tomogram\" : test_tomogram,\n",
    "        \"--num_epochs\" : num_epoch,\n",
    "        \"--DF_weights_path\" : \"results/\" + experiment_name + \"/seed\" + str(N) + \"/\",\n",
    "        \"--out_path\" : \"results/\" + experiment_name + \"/seed\" + str(N) + \"/\", \n",
    "    }\n",
    "    \n",
    "    command = get_full_DF_analysis_command(DF_segmentation_command, analysis_conf)\n",
    "    command_queue.append(command)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c253fbe-9386-4f15-b4b2-a33a77a97357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the commands and store them in queue for clustering and evaluation\n",
    "DF_clustering_command ='python faket/deepfinder/launch_clustering.py'\n",
    "DF_evaluation_command ='python faket/deepfinder/launch_evaluation.py'\n",
    "experiment_name = \"exp1\"\n",
    "seed_ids = [1, 2]\n",
    "num_epochs = [1,2]\n",
    "test_tomograms = [\"baseline\"]\n",
    "num_processes = 2\n",
    "\n",
    "command_queue_clustering = []\n",
    "command_queue_evaluation = []\n",
    "\n",
    "for N, num_epoch, test_tomogram in product(seed_ids, num_epochs, test_tomograms):\n",
    "    analysis_conf ={\n",
    "        \"--test_tomogram\" : test_tomogram,\n",
    "        \"--test_tomo_idx\" : 9,\n",
    "        \"--num_epochs\" : num_epoch,\n",
    "        \"--label_map_path\" : \"results/\" + experiment_name + \"/seed\" + str(N) + \"/\",\n",
    "        \"--out_path\" : \"results/\" + experiment_name + \"/seed\" + str(N) + \"/\", \n",
    "    }\n",
    "    \n",
    "    command_clustering = get_full_DF_analysis_command(DF_clustering_command, analysis_conf)\n",
    "    command_queue_clustering.append(command_clustering)\n",
    "    \n",
    "    command_evaluation = get_full_DF_analysis_command(DF_evaluation_command, analysis_conf)\n",
    "    command_queue_evaluation.append(command_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69396b-5062-49d2-95cd-f8cbbadb5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the clustering\n",
    "num_cpu = 4\n",
    "cpu_id_list = list(range(num_cpu))\n",
    "\n",
    "gpuMultiprocessing.queue_runner(command_queue_clustering, cpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=1, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a1ad9-eed4-49ba-95c0-7e3566c446dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the evaluation\n",
    "num_cpu = 4\n",
    "cpu_id_list = list(range(num_cpu))\n",
    "\n",
    "gpuMultiprocessing.queue_runner(command_queue_evaluation, cpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
