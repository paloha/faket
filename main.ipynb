{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458f1574-baad-428c-971f-eaeebb29863d",
   "metadata": {},
   "source": [
    "# Reproducing FakET experiments on SHREC21 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37efdc36-efcc-479a-9a62-a7eaf087fc15",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Naming convention and contents of the created files\n",
    "\n",
    "1. `faket/class_mask.mrc` = `class_mask.mrc` sliced to valid region.\n",
    "1. `faket/occupancy_mask.mrc` = `occupancy_mask.mrc` slice to valid region.\n",
    "1. `reconstruction.mrc` = `faket/reconstruction_shrec.mrc` slice to valid region for tomogram 9.\n",
    "1. `faket/projections_noiseless.mrc` = `grandmodel_unbinned.mrc` measured with Radon transform.\n",
    "1. `faket/projections_content.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.1) shifted & scaled according its style*.\n",
    "1. `faket/projections_noisy.mrc` = `faket/projections_noiseless.mrc` + noise (std=0.4) shifted & scaled according its style*.\n",
    "1. `faket/projections_styled.mrc` = result of NST initialized with `faket/projections_noisy.mrc`, content `faket/projections_content.mrc`, and using its style*.\n",
    "1. `faket/reconstruction_content.mrc` = reconstruction of `faket/projections_content.mrc`.\n",
    "1. `faket/reconstruction_noisy.mrc` = reconstruction of `faket/projections_noisy.mrc`.\n",
    "1. `faket/reconstruction_styled.mrc` = reconstruction of `faket/projections_styled.mrc`.\n",
    "1. `faket/reconstruction_baseline.mrc` = reconstruction of `projections.mrc`.\n",
    "\n",
    "\\* Each time we mention style in the text above, it refers to a `projections.mrc` file from a model_N+1. In case N=8, the style is taken from N=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37e5a4-b8ed-4087-bd1c-f6b5608e8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f9ad8-f0b4-48cb-a439-c3f3d2ba6dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import gpuMultiprocessing\n",
    "from itertools import product\n",
    "from os.path import join as pj\n",
    "import matplotlib.pyplot as plt\n",
    "from faket.data import get_clim, get_theta\n",
    "from faket.data import match_mean_std, normalize\n",
    "from faket.data import downsample_sinogram_space\n",
    "from faket.data import slice_to_valid, vol_to_valid\n",
    "from faket.data import load_mrc, save_mrc, save_conf\n",
    "from faket.transform import noise_projections\n",
    "from faket.transform import radon_3d, reconstruct_mrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba7269-c7a8-4ada-8cde-2a4893c101a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/shrec2021_extended_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63139552-e378-494b-ad7a-aff7fd6f72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHREC21 provides the data in square shape even\n",
    "# thought the data is stored only in the center\n",
    "# The following values specify where to slice\n",
    "z_valid = (0.32226, 0.67382)  # Valid range normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83450709-63c0-459d-ad7d-98e606b9bfe2",
   "metadata": {},
   "source": [
    "## Slicing volumes to valid voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b557c4-bd47-44d5-80b0-f1e5151c32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice class_mask.mrc to faket/class_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, f'model_{N}', 'class_mask', z_valid, \n",
    "                 out_fname='faket/class_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66b8d9-1636-4ddd-853f-f34ff7012ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice occupancy_mask.mrc to faket/occupancy_mask.mrc\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, f'model_{N}', 'occupancy_mask', z_valid, \n",
    "                 out_fname='faket/occupancy_mask.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce1262-c1e2-4cea-b7d2-90d178bb362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice reconstruction.mrc to faket/reconstruction_shrec.mrc\n",
    "# for sanity-check whether we get similar results from the original challenge data\n",
    "for N in range(10):\n",
    "    vol_to_valid(data_folder, f'model_{N}', 'reconstruction', z_valid, \n",
    "                 out_fname='faket/reconstruction_shrec.mrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087354b7-0d6d-4a99-8170-3ddb28916046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating projections\n",
    "\n",
    "### Noiseless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdde34-b4f6-4c99-a6b6-53d9b6931c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_noiseless.mrc by measuring the grandmodel_unbinned.mrc with Radon transform\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = {\n",
    "        'input_mrc': pj(data_folder, f'model_{N}', 'grandmodel_unbinned.mrc'),\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'),\n",
    "        'radon_kwargs': {\n",
    "            'theta': get_theta(data_folder, N),\n",
    "            'dose': 0,\n",
    "            'out_shape': 1024,\n",
    "            'slice_axis': 1,\n",
    "            # circle=False because we measure with the data outside the circle \n",
    "            # but later we cut the measurements to desired shape \n",
    "            # SHREC did it this way - confirmed from a personal communication\n",
    "            'circle': False\n",
    "        }\n",
    "    }\n",
    "    volume = load_mrc(conf['input_mrc'])\n",
    "    sinogram = radon_3d(volume, **conf['radon_kwargs'])\n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    save_mrc(sinogram.astype(np.float32), conf['output_mrc'], overwrite=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfebcd2-9b16-4a53-b023-24851918bb66",
   "metadata": {},
   "source": [
    "### Noisy & Contnet\n",
    "\n",
    "Adding Gaussian noise in projection space and matching tilt-wise mean&std of style projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dc7f1-7f97-4faf-af7d-d2af39eb93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faket/projections_content.mrc and faket/projections_noisy.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    \n",
    "    # Noisy modality\n",
    "    conf = {\n",
    "        'input_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'),\n",
    "        'style_mrc': pj(data_folder, f'model_{style_N}', 'projections.mrc'),\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_noisy.mrc'),\n",
    "        'mean': 0.0,\n",
    "        'std': 0.4,\n",
    "        'clip_outliers': (0.0001, 0.9999),\n",
    "        'seed': N,\n",
    "    }\n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    noise_projections(**conf)\n",
    "    \n",
    "    # Content modality\n",
    "    conf2 = {\n",
    "        'output_mrc': pj(data_folder, f'model_{N}', 'faket/projections_content.mrc'),\n",
    "        'std': 0.1,\n",
    "    }\n",
    "    conf.update(conf2)\n",
    "    save_conf(conf['output_mrc'], conf)\n",
    "    noise_projections(**conf)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248df2ef-3676-4052-86a6-0947bf7b0ca5",
   "metadata": {},
   "source": [
    "### Styled\n",
    "\n",
    "Neural Style Transfer in projection space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486594b9-51a9-450f-b259-7ecc10881ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_queue_nst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927792d-dd97-409b-a1c6-67e7952f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstc = {  # NEURAL STYLE TRANSFER BASE CONFIG\n",
    "    # The commented params will be set later\n",
    "    # 'content': 'example.mrc',\n",
    "    # 'style': 'example.mrc',\n",
    "    # '--init': 'example.mrc',\n",
    "    # '--output': 'example.mrc', \n",
    "    # '--random-seed': None,\n",
    "    '--style-weights': 1.0,  # if number of style images is 1, 1.0 is the same as None\n",
    "    '--content-weight': 1.0,  # weight of the content loss relative to style loss\n",
    "    '--tv-weight': 0,\n",
    "    '--min-scale': 1024,\n",
    "    '--end-scale': 1024,\n",
    "    '--iterations': 1,\n",
    "    '--initial-iterations': 1,\n",
    "    '--save-every': 2,\n",
    "    '--step-size': 0.15,\n",
    "    '--avg-decay': 0.99,\n",
    "    '--style-scale-fac': 1.0,\n",
    "    '--pooling': 'max',\n",
    "    '--devices': 'cuda:0', #\n",
    "    '--seq_start' : 0,\n",
    "    '--seq_end' : 61,\n",
    "    '--content_layers': '8 11',\n",
    "    '--content_layers_weights': '67 33'\n",
    "}\n",
    "\n",
    "def get_command(expname, nst_command, config):\n",
    "    command = (\n",
    "    f\"EXPNAME={expname} {nst_command} \"\n",
    "    f\"{config['content']} {config['style']} \"\n",
    "    f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])}\")\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94bfe9-cecf-4260-b185-843fa356d199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create faket/projections_styled.mrc\n",
    "gpu_id_list = [0, 4, 5, 6, 7]\n",
    "NST_command = 'PYTHONHASHSEED=0 python3 -m faket.style_transfer.cli'\n",
    "\n",
    "# command_queue_nst = []\n",
    "for N in range(0, 9): # We do not need this modality for the test model_9\n",
    "    style_N = (N + 1) % 9 # For the last train model we take style stats from the first train model\n",
    "    \n",
    "    EXPNAME = f'TOMOGRAM_{N}'  # Just for visualizing the progress\n",
    "    tomo_folder = pj(data_folder, f'model_{N}', 'faket')\n",
    "\n",
    "    conf = nstc.copy()\n",
    "    conf.update({\n",
    "        'content': pj(tomo_folder, 'projections_content.mrc'),\n",
    "        'style': pj(data_folder, f'model_{style_N}', 'projections.mrc'), \n",
    "        '--init': pj(tomo_folder, 'projections_noisy.mrc'),\n",
    "        '--output': pj(tomo_folder, 'projections_styled.mrc'), \n",
    "        '--random-seed': N,\n",
    "    })\n",
    "    \n",
    "    command = get_command(EXPNAME, NST_command, conf)\n",
    "    command_queue_nst.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4708ec-d1dd-4a03-81a9-ac061af723da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the command queue to a file\n",
    "with open('command_queue_nst.txt', 'w') as fl:\n",
    "    fl.writelines('\\n'.join(command_queue_nst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff842e88-f0e0-4119-9376-702eb70642db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue_nst, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=6, allowed_restarts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808e94a-4e7b-439c-ad2b-c0fac8ed86be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computing reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63637366-ba08-408e-8dc2-473fd13a328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recc = {  # RECONSTRUCTION BASE CONFIG\n",
    "    'downsample_angle' : 1,  # Sinogram downsampling in theta dimension (1 = no downsampling)\n",
    "    'downsample_pre' : 2,  # Sinogram downsampling (1 = no downsampling)\n",
    "    'order' : 3,  # Downsampling in space with spline interpolation of order (0 - 5)\n",
    "    'filtering' : 'ramp2d',  # Filter used during reconstruction in FBP algorithm\n",
    "    'filterkwargs' : {'crowtherFreq': 25, 'radiusCutoff': 230, 'angularCutoff': (0, 83)},\n",
    "    'downsample_post' : 1,  # Reconstruction downsampling\n",
    "    'ncpus': 61, # multiprocessing.cpu_count(),  # Number of CPUs to use while reconstructing\n",
    "    'z_valid': z_valid # 2-tuple range of valid pixels in Z dimension normalized from 0 to 1. (0., 1.) or None for all.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797c6ea-1299-4e6b-b135-75043cf73a5b",
   "metadata": {},
   "source": [
    "### Noiseless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037af53-80ca-4a9c-a2c2-8682d308454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_noiseless.mrc to produce faket/reconstruction_noiseless.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'faket/projections_noiseless.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_noiseless.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8983423-faed-4e3a-9cad-27434d8734e3",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68c034-b3e5-4f7b-9c3e-567b57e3b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct projections.mrc to produce faket/reconstruction_baseline.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'projections.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_baseline.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200fe14a-1019-46da-8f36-c996c1161774",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cc94e-b2ab-44b7-982d-bbfc0a90a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_content.mrc to produce faket/reconstruction_content.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' :  pj(data_folder, f'model_{N}', 'faket/projections_content.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' :  pj(data_folder, f'model_{N}', 'faket/reconstruction_content.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0a746-77fc-4b29-8cf7-b3298a4c7d88",
   "metadata": {},
   "source": [
    "### Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b252a9-1d7f-4357-9e70-2f068a815f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_noisy.mrc to produce faket/reconstruction_noisy.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : pj(data_folder, f'model_{N}', 'faket/projections_noisy.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', 'faket/reconstruction_noisy.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b422aef-9cd0-4a6c-b906-1d0b3cfb49f0",
   "metadata": {},
   "source": [
    "### Styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c2fbf-abf6-4316-a492-b92601a7c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct faket/projections_styled.mrc to produce faket/reconstruction_styled.mrc\n",
    "for N in range(0, 10):\n",
    "    print(f'Processing N: {N}')\n",
    "    conf = recc.copy()\n",
    "    conf.update({\n",
    "        'input_mrc' : pj(data_folder, f'model_{N}', f'faket/projections_styled.mrc'), \n",
    "        'theta': pj(data_folder, f'model_{N}', 'alignment_simulated.txt'), \n",
    "        'output_mrc' : pj(data_folder, f'model_{N}', f'faket/reconstruction_styled.mrc.mrc')\n",
    "    })\n",
    "    reconstruct_mrc(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6dd1b-e678-4874-99ce-d3ed44155600",
   "metadata": {},
   "source": [
    "# Deep Finder experiments\n",
    "\n",
    "Train for 30 epochs on 9 tomograms, eval on validation (last training) tomogram at every epoch\n",
    "\n",
    "1. `DF('faket/reconstruction_baseline.mrc')` \n",
    "2. `DF('faket/reconstruction_content.mrc')`\n",
    "3. `DF('faket/reconstruction_noisy.mrc')`\n",
    "4. `DF('faket/reconstruction_styled.mrc')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224fcff-a658-4dd9-bbcc-ea9b6ec057a8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c78ccc-cd0b-462d-96fc-d4b517bdb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_DF_training_command(DF_training_command, config):\n",
    "    command = (\n",
    "        f\"{DF_training_command} \"\n",
    "        f\"--training_tomogram_ids {' '.join(list(zip(*config['training_tomograms']))[0])} \"\n",
    "        f\"--training_tomograms {' '.join(list(zip(*config['training_tomograms']))[1])} \"\n",
    "        f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])} \"       \n",
    "    )\n",
    "    return command\n",
    "\n",
    "command_queue_training = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa266a-6e18-44ef-997b-4944b527e5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the training (each job runs on one GPU, but more GPUs can run more jobs in parallel)\n",
    "gpu_id_list = [0, 1, 2, 3, 4, 5]\n",
    "DF_training_command ='PYTHONHASHSEED=0 python3 faket/deepfinder/launch_training.py'\n",
    "\n",
    "# create config files from dict using json for different seeds\n",
    "for idf in ['shrec']: #['_CL[6]_CLW[100]', '_CL[8]_CLW[100]', '_CL[11]_CLW[100]', '_CL[8,11]_CLW[67,33]', '_CL[8,11]_CLW[33,67]']:\n",
    "\n",
    "    experiment_names = [f'exp_baseline_{idf}']\n",
    "    training_tomograms = [f'{idf}']\n",
    "\n",
    "    num_seeds = 10\n",
    "    num_epochs = 30\n",
    "\n",
    "    # command_queue = []\n",
    "    for experiment_name, training_tomogram in zip(experiment_names, training_tomograms):\n",
    "        for N in range(1, num_seeds + 1):\n",
    "            training_conf = {\n",
    "                \"--training_tomo_path\": data_folder,\n",
    "                \"training_tomograms\": [[str(i), training_tomogram] for i in range(0,9)],\n",
    "                \"--num_epochs\": num_epochs,\n",
    "                \"--out_path\": pj('data', 'results', experiment_name, f'seed{N}'),\n",
    "                \"--save_every\": 1, \n",
    "                \"--seed\": N,\n",
    "                # If continue_training_path is the same as out_path - continue from last epoch.\n",
    "                # If it is a path to a specific weights.h5 file, continue from there.\n",
    "                \"--continue_training_path\": pj('data', 'results', experiment_name, f'seed{N}'),\n",
    "\n",
    "            }\n",
    "            command = get_full_DF_training_command(DF_training_command, training_conf)\n",
    "            command_queue_training.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5b902-41c1-47b9-ad1c-ba38310fa03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the command queue to a file\n",
    "with open('command_queue_training_baseline_shrec.txt', 'w') as fl:\n",
    "    fl.writelines('\\n'.join(command_queue_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec982ff-ef38-40fd-a4b3-5a319d8306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99fc5a-c6b3-4fe2-97b2-3f3891557c21",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bf698-b2ae-44de-8574-265ec3913ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_DF_analysis_command(DF_analysis_command, config):\n",
    "    command=(\n",
    "        f\"{DF_analysis_command} \"\n",
    "        f\"{' '.join([f'{k} {v}' for k, v in config.items() if k.startswith('--')])}\"\n",
    "    )\n",
    "    return command\n",
    "\n",
    "command_queue_segmentation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537ca48-9d2b-429f-a4c8-a6dd97b4be2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the segmentation (each job runs on one GPU, but more GPUs can run more jobs in parallel)\n",
    "gpu_id_list = [0, 4, 5, 6, 7]\n",
    "\n",
    "DF_segmentation_command ='PYTHONHASHSEED=0 python3 faket/deepfinder/launch_segmentation.py'\n",
    "\n",
    "#experiment_names = ['exp_volnoisy']\n",
    "seed_ids = range(1, 11)\n",
    "num_epochs = range(1, 31)\n",
    "test_tomograms = ['shrec']\n",
    "test_tomo_idx = 9\n",
    "\n",
    "for idf in ['shrec']: #['_CL[6]_CLW[100]', '_CL[8]_CLW[100]', '_CL[11]_CLW[100]', '_CL[8,11]_CLW[67,33]', '_CL[8,11]_CLW[33,67]']:\n",
    "    experiment_names = [f'exp_baseline_{idf}']#[f'exp_styled{idf}']\n",
    "\n",
    "    # command_queue_segmentation = []\n",
    "    for N, num_epoch, test_tomogram, experiment_name in \\\n",
    "        product(seed_ids, num_epochs, test_tomograms, experiment_names):\n",
    "        analysis_conf ={\n",
    "            \"--test_tomo_path\" : data_folder,\n",
    "            \"--test_tomo_idx\" : test_tomo_idx, \n",
    "            \"--test_tomogram\" : test_tomogram,\n",
    "            \"--num_epochs\" : num_epoch,\n",
    "            \"--DF_weights_path\" : pj('data', 'results', experiment_name, f'seed{N}'),\n",
    "            \"--out_path\" : pj('data', 'results', experiment_name, f'seed{N}'), \n",
    "        }\n",
    "        command = get_full_DF_analysis_command(DF_segmentation_command, analysis_conf)\n",
    "        command_queue_segmentation.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30565a-5df9-4d6c-ad82-1fffc74db22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the command queue to a file\n",
    "with open('command_queue_segmentation_baseline_shrec.txt', 'w') as fl:\n",
    "    fl.writelines('\\n'.join(command_queue_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f836dc-0e8a-49fc-83ad-7c3ec84b8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the commands (returns list of failed commands if any)\n",
    "gpuMultiprocessing.queue_runner(command_queue_segmentation, gpu_id_list,\n",
    "                                env_gpu_name='CUDA_VISIBLE_DEVICES',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811eb7f0-b743-4614-b5c9-63e1569c3cdd",
   "metadata": {},
   "source": [
    "## Clustering & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a51e7-b337-4962-924e-92582263e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the evaluation, make sure that `particle_locations.txt` file is present in the test tomogram folder.\n",
    "for model in ['model_8', 'model_9']:\n",
    "    src = pj(data_folder, model, 'particle_locations.txt')\n",
    "    dst = pj(data_folder, model, 'faket', 'particle_locations.txt')\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba74848-fab5-4575-9c3c-4a9e702a58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_queue_clustering = []\n",
    "command_queue_evaluation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c253fbe-9386-4f15-b4b2-a33a77a97357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the commands and store them in queue for clustering and evaluation\n",
    "DF_clustering_command ='python3 faket/deepfinder/launch_clustering.py'\n",
    "DF_evaluation_command ='python3 faket/deepfinder/launch_evaluation.py'\n",
    "# experiment_names = [\"exp_volnoisy\"]\n",
    "seed_ids = range(1, 11)\n",
    "num_epochs = range(1, 31)\n",
    "test_tomograms = ['shrec']\n",
    "test_tomo_idx = 9\n",
    "\n",
    "for idf in ['shrec']: #['_CL[6]_CLW[100]', '_CL[8]_CLW[100]', '_CL[11]_CLW[100]', '_CL[8,11]_CLW[67,33]', '_CL[8,11]_CLW[33,67]']:\n",
    "    experiment_names = [f'exp_baseline_{idf}']\n",
    "    for N, num_epoch, test_tomogram, experiment_name \\\n",
    "        in product(seed_ids, num_epochs, test_tomograms, experiment_names):\n",
    "        analysis_conf ={\n",
    "            \"--test_tomogram\" : test_tomogram,\n",
    "            \"--test_tomo_idx\" : test_tomo_idx,\n",
    "            \"--num_epochs\" : num_epoch,\n",
    "            \"--label_map_path\" : pj('data', 'results', experiment_name, f'seed{N}'),\n",
    "            \"--out_path\" : pj('data', 'results', experiment_name, f'seed{N}'), \n",
    "        }\n",
    "\n",
    "        command_clustering = get_full_DF_analysis_command(DF_clustering_command, analysis_conf)\n",
    "        command_queue_clustering.append(command_clustering)\n",
    "\n",
    "        command_evaluation = get_full_DF_analysis_command(DF_evaluation_command, analysis_conf)\n",
    "        command_queue_evaluation.append(command_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77453804-f646-49aa-81d7-cda972007bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the command queue to a file\n",
    "with open('command_queue_clustering_baseline_shrec.txt', 'w') as fl:\n",
    "    fl.writelines('\\n'.join(command_queue_clustering))\n",
    "    \n",
    "# Save the command queue to a file\n",
    "with open('command_queue_evaluation_baseline_shrec.txt', 'w') as fl:\n",
    "    fl.writelines('\\n'.join(command_queue_evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69396b-5062-49d2-95cd-f8cbbadb5a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the clustering (each job runs on one CPU, but more CPUs can run more jobs in parallel)\n",
    "num_cpus = 100\n",
    "cpu_id_list = list(range(num_cpus))\n",
    "\n",
    "gpuMultiprocessing.queue_runner(command_queue_clustering, cpu_id_list,\n",
    "                                env_gpu_name='CPUID',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a1ad9-eed4-49ba-95c0-7e3566c446dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the evaluation (each job runs on one CPU, but more CPUs can run more jobs in parallel)\n",
    "num_cpus = 100\n",
    "cpu_id_list = list(range(num_cpus))\n",
    "\n",
    "gpuMultiprocessing.queue_runner(command_queue_evaluation, cpu_id_list,\n",
    "                                env_gpu_name='CPUID',\n",
    "                                processes_per_gpu=2, allowed_restarts=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
